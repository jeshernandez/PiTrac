**PiTrac Automated Testing**

This document describes how to setup PiTrac’s automated testing.

PiTrac’s automated testing supports the comparison of final ball results (velocity, back-spin, etc.) computed from the teed-ball and strobed images, to a set of expected values from a comma-separated file.  The expected values are typically generated by another launch monitor that was used in conjunction with PiTrac to provide “ground-truth” data against which to compare PiTrac results.  Alternatively, the expected data can be computed manually with a good eye, an on-screen protractor, and a little algebra.

**How to setup for automated testing:**  
To prepare a test suite (a set of result and expected value sets), create a directory that contains the following (details further below):

1. An “expected values” file corresponding to expected values for each of the primary shot value elements for each (numbered) shot.  
2. Image files (from the diagnostic image outputs of PiTrac) that correspond to the teed-ball and strobed ball images for each of the shots in the expected value file.  These are the images that were taken by PiTrac when the ground-truth data was determined.  To tie the testing together, each filename must contain a shot number corresponding to each line of the expected values file as well as a certain prefix.  Only one pair of images can have the same shot number.  For example, with “\*” representing any other text, the pattern of image pairs look like:

   1. gs\_log\_img\_\_log\_ball\_final\_found\_ball\_img\_Shot\_1\_\*.png  
   2. gs\_log\_img\_\_log\_cam2\_last\_strobed\_img\_Shot\_1\_\*.png

   The Image files are produced by PiTrac automatically when the "logging": "kLogDiagnosticImagesToUniqueFiles": is set to 1\.  For example, the following files are examples of those produced corresponding to the picture of the teed-up ball and the picture of the strobed balls, repsectively.  These are the files that are necessary to test each shot:

   3. gs\_log\_img\_\_log\_ball\_final\_found\_ball\_img\_Shot\_1\_2025-Feb-07\_11.03.49.png  
   4. gs\_log\_img\_\_log\_cam2\_last\_strobed\_img\_Shot\_1\_2025-Feb-07\_11.03.12.png

3. The golf\_sim\_config.json file that was used when the images and data in the test suite were generated.  Keeping a copy of the .json file here will ensure that when other values change later, you can always reproduce the setup that was used when the images were generated.

Next, set the file directory name and the names of the input (expected values) file and output file into the config file.  Specifically, set tolerances, input and output files and the test directory as follows in an example golf\_sim\_config.json file:

"testing": {  
…  
	"kAutomatedTestSuiteDirectory": "M:/Dev/PiTrac/Software/LMSourceCode/Testing/TestSuite\_2025\_02\_07/",  
	"kAutomatedTestExpectedResultsCSV": "Uneekor Comparison 2025-02-07\_Small\_Test.csv",  
	"kAutomatedTestResultsCSV": "PiTrac\_Test\_Results.csv",  
	"kAutomatedTestToleranceBallSpeedMPH": 4,  
	"kAutomatedTestToleranceHLA": 3,  
	"kAutomatedTestToleranceVLA": 2,  
	"kAutomatedTestToleranceBackSpin": 250,  
	"kAutomatedTestToleranceSideSpin": 300,

The tolerances are the value that–above which–the difference between PiTrac’s number and the expected results file will result in the test being considered a failure.

Finally, make sure that PiTrac–when run–will use the same golf\_sim\_config.json file that is stored in the test suite directory.

The format of the expected-values input .csv file is as follows, but with commas between the values.  Shown below first is how the file would look in Excel, and then the raw file:

Shot	Speed	VLA	HLA	Back Spin	Side Spin	Ignore  
1	66.6	19.1	\-5.6	3987		\-355		FALSE  
2	54.5	10.9	\-4	1686		\-1048		TRUE  
3	60.5	14.5	\-5.5	2137		\-1421		FALSE

So, in raw format:  
Shot,Speed,VLA,HLA,Back Spin,Side Spin,Ignore  
1,66.6,19.1,-5.6,3987,-355,  
2,54.5,10.9,-4,1686,-1048,TRUE  
3,60.5,14.5,-5.5,2137,-1421,

If “Ignore” is set to TRUE, the automated testing will skip over that shot.  This can be useful when you know that certain images did not really work out (perhaps because of interference from an external strobing system).  The input .csv file should be easy to create from the output of most golf sims.  If your sim uses Left and Right side spin designators, an Excel formula like the following will work to convert to the signed integer format used by the PiTrac .csv file  (for example for Cell K5 in a different spreadsheet called “Uneekor”:

\=IF(LEFT(Uneekor\!K5,1)="R",1,-1)\*NUMBERVALUE((RIGHT(LEFT(Uneekor\!K5,LEN(Uneekor\!K5)-1),4)))

**How to run automated testing:**  
To run the test to process the image files and compare the computed ball-shot results to the expected results, you can run PiTrac in either Linux or Windows.  Running in Windows under Visual Studio may help in debugging any problems.  When running PiTrac, use the mode in the following example,, and (generally) info-level logging:

pitrac \--show\_images 1  \--base\_image\_logging\_dir L:\\ \--lm\_comparison\_mode=1 **\--logging\_level info**  \--artifact\_save\_level=all \--wait\_keys 0 **\--system\_mode automated\_testing**  \--search\_center\_x 800  \--search\_center\_y 550

Generally, the images that will be used will be images generated when PiTrac was running alongside another tracking system.  If the other tracking system uses IR strobing (like a Uneekor Eye XO, for example), you will want to set “\-lm\_comparison\_mode=1” to try to compensate for the brighter resulting images.

The output .csv file (which will be named as the value in kAutomatedTestResultsCSV) has the following format:

Shot ID		Comparison (PiTrac value minus Uneekor)						System Data																	  
Ball	 PiTrac Shot	 Speed ? (mph)	 VLA ? 	 HLA ? °	 Back Spin ? (rpm)	 Side Spin ? (rpm)	 	 Uneekor Speed	 PiTrac Speed	 	 Uneekor VLA°	 PiTrac VLA°	 	 Uneekor HLA°	 PiTrac HLA°	 	 Uneekor Back Spin	 PiTrac Back Spin	 	 Uneekor Side Spin	 PiTrac Side Spin	 	 Ball ID Picture	 Spin Ball 1	 Spin Ball 2  
	1	\-2.58109	0.218401	\-0.980485	\-336	\-1073	 	66.6	64.0189	 	19.1	18.1195	 	\-5.6	\-5.3816	 	3987	3650.79	 	\-355	\-1428.57	FAIL			  
 	 	 	 															  
	2																								  
	3	\-3.91849	\-2.07088	\-0.631305	\-602	\-60	 	60.5	56.5815	 	14.5	13.8687	 	\-5.5	\-7.57088	 	2137	1534.39	 	\-1421	\-1481.48	FAIL			  
